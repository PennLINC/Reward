<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/assets/css/just-the-docs-default.css"> <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script> <script type="text/javascript" src="/assets/js/just-the-docs.js"></script><meta name="viewport" content="width=device-width, initial-scale=1"><title>Data Narrative | Reward Project Documentation</title><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="Data Narrative" /><meta property="og:locale" content="en_US" /><meta name="description" content="Documentation of Reward Data Processing and Analysis" /><meta property="og:description" content="Documentation of Reward Data Processing and Analysis" /><link rel="canonical" href="http://localhost:4000/projects/day2/datanarrative/" /><meta property="og:url" content="http://localhost:4000/projects/day2/datanarrative/" /><meta property="og:site_name" content="Reward Project Documentation" /><meta property="og:type" content="website" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Data Narrative" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Documentation of Reward Data Processing and Analysis","headline":"Data Narrative","url":"http://localhost:4000/projects/day2/datanarrative/"}</script><body> <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> <symbol id="svg-link" viewBox="0 0 24 24"><title>Link</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"><title>Search</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"><title>Menu</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"><title>Expand</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"><polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"><title>Document</title><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"><path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> </svg><div class="side-bar"><div class="site-header"> <a href="http://localhost:4000/" class="site-title lh-tight"> Reward Project Documentation </a> <a href="#" id="menu-button" class="site-button"> <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg> </a></div><nav role="navigation" aria-label="Main" id="site-nav" class="site-nav"><ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Home</a><li class="nav-list-item"><a href="http://localhost:4000/anna/" class="nav-list-link">Legacy Curation (2018-2020)</a><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/neff/neff_index/" class="nav-list-link">NEFF V1 & V2</a><ul class="nav-list "></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/fndm1/fndm1_index/" class="nav-list-link">FNDM1</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/projects/fndm1/datanarrative/" class="nav-list-link">Data Narrative</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/fndm2/fndm2_index/" class="nav-list-link">FNDM2</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/projects/fndm2/datanarrative/" class="nav-list-link">Data Narrative</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/nodra/nodra_index/" class="nav-list-link">Nodra</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/projects/nodra/datanarrative/" class="nav-list-link">Data Narrative</a></ul><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/day2/day2_index/" class="nav-list-link">Day2</a><ul class="nav-list "><li class="nav-list-item active"><a href="http://localhost:4000/projects/day2/datanarrative/" class="nav-list-link active">Data Narrative</a></ul><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/projects/cogtrain/cogtrain_index/" class="nav-list-link">CogTrain</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/projects/cogtrain/datanarrative/" class="nav-list-link">Data Narrative</a><li class="nav-list-item "><a href="http://localhost:4000/projects/cogtrain/itc_task_events/" class="nav-list-link">ITC Task Events</a></ul></ul></nav><footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</footer></div><div class="main" id="top"><div id="main-header" class="main-header"><div class="search"><div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Reward Project Documentation" aria-label="Search Reward Project Documentation" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label></div><div id="search-results" class="search-results"></div></div><nav aria-label="Auxiliary" class="aux-nav"><ul class="aux-nav-list"><li class="aux-nav-list-item"> <a href="//github.com/PennLINC/Reward" class="site-button" > Edit on GitHub </a></ul></nav></div><div id="main-content-wrap" class="main-content-wrap"><nav aria-label="Breadcrumb" class="breadcrumb-nav"><ol class="breadcrumb-nav-list"><li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/projects/day2/day2_index/">Day2</a><li class="breadcrumb-nav-list-item"><span>Data Narrative</span></ol></nav><div id="main-content" class="main-content" role="main"><h2 id="data-narrative-for-day2---margarets-curation"> <a href="#data-narrative-for-day2---margarets-curation" class="anchor-heading" aria-labelledby="data-narrative-for-day2---margarets-curation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data Narrative for DAY2 - Margaret’s Curation</h2><h3 id="data-processing-flow--important-links"> <a href="#data-processing-flow--important-links" class="anchor-heading" aria-labelledby="data-processing-flow--important-links"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data Processing Flow &amp; Important Links:</h3><ul><li>Flow diagram that describes the lifecycle of this dataset curation and preprocessing may be viewed <a href="https://github.com/PennLINC/DAY2_Margaret/blob/c45c9e9e6a7837f698f430677cf323aca0395f5e/Day2%20Project%20Update.pdf">here</a><li><strong>Overview:</strong><ul><li>subjects without usable fmaps (no SDC run in fMRIPrep): ‘sub-12235’ ‘sub-13585’ ‘sub-14610’ ‘sub-14848’ ‘sub-14858’ ‘sub-14876’ ‘sub-15546’ ‘sub-16181’ ‘sub-16234’ ‘sub-17726’ *scans noted <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/NoFmaps.ipynb">here</a><li>subjects/scans that failed fMRIPrep: sub-13373_ses-day2_task-face_run-01_bold.nii.gz, sub-14858_ses-day2_task-card_run-02_bold.nii.gz, sub-15709_ses-day2_task-rest_bold.nii.gz <em>note: gzip error, can be rerun with later version</em><li>subjects/scans with poor QC: sub-15433 T1w (euler=782); sub-17378 card1, card2, face1, face2 (normCrossCorr &lt;0.8); sub-15276 face2 (normCrossCorr &lt;0.8); sub-15433 card 2 (normCrossCorr &lt;0.8); <em>note: paths to XCP-generated .html reports for each subject and concatenated qc values provided below</em></ul><li>DSR GitHub Project Page(Curation/Validation and Processing Queue Status):<ul><li>Cards for tracking the curation and validation portion of the dataset. This page should be updated every time you perform an action on the data.<li>Cards for tracking the progress of containerized pipeline runs on the data.</ul></ul><h3 id="plan-for-the-data"> <a href="#plan-for-the-data" class="anchor-heading" aria-labelledby="plan-for-the-data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Plan for the Data</h3><ul><li>Why does PennLINC need this data?<li>For which project(s) is it intended? Please link to project pages below:<li>Goal is to curate and preprocess data</ul><h3 id="data-acquisition"> <a href="#data-acquisition" class="anchor-heading" aria-labelledby="data-acquisition"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Data Acquisition</h3><ul><li>Data acquired by Dan Wolf<li>Describe the data:<ul><li>number of subjects = 125<li>types of images = bold (2 runs task-face, 2 runs task-card, rest), T1w, T2w, DWI <em>note: run1=task version A and run2 = task version B according to json SeriesDescription, see <a href="https://github.com/PennLINC/DAY2_Margaret/blob/f35fb7bdb2422b72d42d9328dd5644e7b5ddba12/notebooks/task-match.ipynb">task-match.ipynb</a></em><ul><li>T1w = 125 subj<li>T2w = 3 subj<li>card_run-01 = 124 subj<li>card_run-02 = 124 subj<li>face_run-01 = 123 subj<li>face_run-02 = 124 subj<li>rest = 114 subj<li>fmap = 124 subj<li>dwi = 3 subj</ul></ul></ul><h3 id="download-and-storage"> <a href="#download-and-storage" class="anchor-heading" aria-labelledby="download-and-storage"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Download and Storage</h3><ul><li>Data was stored as nifti files in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/original_data/bidsdatasets/day2</code>.<li>Data was copied by Margaret to sub-project folder <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/original_data</code> on 9/14/2021.<li><p>JSON’s within origial_data were updated using <code class="language-plaintext highlighter-rouge">cubids-add-nifti-info</code>.</p><li>Listing metadata fields using <code class="language-plaintext highlighter-rouge">cubids-print-metadata-fields</code> resulted:<ul><li>Acknowledgements<li>AcquisitionMatrixPE<li>AcquisitionNumber<li>Authors<li>BIDSVersion<li>BandwidthPerPixelPhaseEncode<li>BaseResolution<li>CoilString<li>ConversionSoftware<li>ConversionSoftwareVersion<li>DatasetDOI<li>DeidentificationMethod<li>DerivedVendorReportedEchoSpacing<li>DeviceSerialNumber<li>Dim1Size<li>Dim2Size<li>Dim3Size<li>DwellTime<li>EchoNumber<li>EchoTime<li>EchoTime1<li>EchoTime2<li>EchoTrainLength<li>EffectiveEchoSpacing<li>FlipAngle<li>Funding<li>HowToAcknowledge<li>ImageOrientationPatientDICOM<li>ImageType<li>ImagingFrequency<li>InPlanePhaseEncodingDirectionDICOM<li>IntendedFor<li>InversionTime<li>License<li>MRAcquisitionType<li>MagneticFieldStrength<li>Manufacturer<li>ManufacturersModelName<li>Modality<li>Name<li>NumVolumes<li>Obliquity<li>ParallelReductionFactorInPlane<li>PartialFourier<li>PercentPhaseFOV<li>PhaseEncodingDirection<li>PhaseEncodingSteps<li>PhaseResolution<li>PixelBandwidth<li>ProcedureStepDescription<li>ProtocolName<li>PulseSequenceDetails<li>ReceiveCoilName<li>ReconMatrixPE<li>RefLinesPE<li>ReferencesAndLinks<li>RepetitionTime<li>SAR<li>ScanOptions<li>ScanningSequence<li>SequenceName<li>SequenceVariant<li>SeriesDescription<li>SeriesInstanceUID<li>SeriesNumber<li>ShimSetting<li>SliceThickness<li>SliceTiming<li>SoftwareVersions<li>SpacingBetweenSlices<li>TaskName<li>TotalReadoutTime<li>TxRefAmp<li>VoxelSizeDim1<li>VoxelSizeDim2<li>VoxelSizeDim3<li>template</ul><p>Running <code class="language-plaintext highlighter-rouge">cubids-remove-metadata-fields</code> resulted no PHI fields for removal.</p><li>Data checked into DataLad <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS (dataset)</code> via <code class="language-plaintext highlighter-rouge">datalad save -m "add initial data" -d ./curation/BIDS</code> <code class="language-plaintext highlighter-rouge">action summary: add (ok: 2448) save (ok: 1)</code></ul><h3 id="curation-process"> <a href="#curation-process" class="anchor-heading" aria-labelledby="curation-process"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Curation Process</h3><ul><li>Data curation by Margaret Gardner for NGG rotation on the CUBIC project user <code class="language-plaintext highlighter-rouge">wolfsatterthwaitereward</code><li>Link to final CuBIDS csvs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration6</code></ul><h4 id="bids-validation"> <a href="#bids-validation" class="anchor-heading" aria-labelledby="bids-validation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> BIDS Validation:</h4><ul><li><p>Iteration 1 (Ran <code class="language-plaintext highlighter-rouge">cubids-validate</code> and <code class="language-plaintext highlighter-rouge">cubids-group</code> simultanously as per The WAY, outputs saved to <code class="language-plaintext highlighter-rouge">sandbox/validator_outputs/iteration1</code>): EVENTS_TSV_MISSING ( Task scans should have a corresponding events.tsv file. If this is a resting state scan you can ignore this warning or rename the task to include the word “rest”. ) : 495 counts INCONSISTENT_SUBJECTS ( Not all subjects contain the same files. Each subject should contain the same number of files with the same naming unless some files are known to be missing. ) : 806 counts INCONSISTENT_PARAMETERS ( Not all subjects/sessions/runs have the same scanning parameters. ) : 24 subjects README_FILE_MISSING ( The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. ) : 1 subjects NO_AUTHORS ( The Authors field of dataset_description.json should contain an array of fields - with one author per field. This was triggered because there are no authors, which will make DOI registration from dataset metadata impossible. ) : 1 subjects</p><li><p>Iteration 1.2 (Reran <code class="language-plaintext highlighter-rouge">cubids-validate</code> with <code class="language-plaintext highlighter-rouge">--ignore_nifti_headers</code> and <code class="language-plaintext highlighter-rouge">--ignore_subject_consistency</code>, no modifications to datafiles): EVENTS_TSV_MISSING ( Task scans should have a corresponding events.tsv file. If this is a resting state scan you can ignore this warning or rename the task to include the word “rest”. ) : 495 scans README_FILE_MISSING ( The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. ) : 1 count NO_AUTHORS ( The Authors field of dataset_description.json should contain an array of fields - with one author per field. This was triggered because there are no authors, which will make DOI registration from dataset metadata impossible. ) : 1 count</p><p>*counts using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a></p><li><p>BIDS curation approved by Ted Satterthwaite and Tinashe Tapera on 9/21/21, last validator output of original data available at <code class="language-plaintext highlighter-rouge">/gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/d2_r2_validation.csv</code>. Data backed up to datalad.</p></ul><h4 id="bids-optimization"> <a href="#bids-optimization" class="anchor-heading" aria-labelledby="bids-optimization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> BIDS Optimization:</h4><p>*NOTE: any files removed from <code class="language-plaintext highlighter-rouge">curation/BIDS</code> dataset noted in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/curation_*_cmd.sh</code> scripts, which are written by <code class="language-plaintext highlighter-rouge">cubids-purge</code>. Any files renamed (Acquisition Variants) noted in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply*_cmd.sh</code> scripts, which are written by <code class="language-plaintext highlighter-rouge">cubids-apply</code>.</p><ul><li>BIDs groups from Iteration 1.2 reviewed by Ted and Tinashe<ul><li>reviewed subject files for duplicates, no subj with more than one T1w or each type of fmap (phase1, phase2, magnitude1, magnitude2)<li><ul><li>118 subj have full set of phase1&amp;2, magnitude1&amp;2 files</ul><li><ul><li>5 subj have only phasediff files (mislabeled phase1) but no magnitude files</ul><li><ul><li>1 subj has only phase1 &amp; phase2 files but no magnitude files</ul><li>identified 3 subjects who have T2 data (KeyParamGroup=datatype-anat_suffix-T2w__1) in addition to T1 that compromise AcqGroup 3<li>Plan to add A/B designation task entity for files to disambiguate task version (cardA,cardB, faceA, or faceB) performed during each run. Data currently contained in SeriesDescription, see <a href="https://github.com/PennLINC/DAY2_Margaret/blob/f35fb7bdb2422b72d42d9328dd5644e7b5ddba12/notebooks/task-match.ipynb">task-match.ipynb</a> *counts using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a> *</ul><li>Iteration 2<ul><li>made sure all files in curation/BIDS checked into datalad<li>T2 files to be removed written to code/sandbox/T2w.txt using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a>, ran <code class="language-plaintext highlighter-rouge">cubids-purge</code>: <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/T2w.txt</code><li>fmap files to be removed written to <code class="language-plaintext highlighter-rouge">Margaret/Day2/curation/code/sandbox/validator_outputs/iteration1.2/fmap_to_rm.txt</code> using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a>, ran <code class="language-plaintext highlighter-rouge">cubids-purge</code>: <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/iteration1.2/fmap_to_rm.txt</code><li>Reran <code class="language-plaintext highlighter-rouge">cubids-validator</code> iter2 with <code class="language-plaintext highlighter-rouge">--ignore_nifti_headers</code> and <code class="language-plaintext highlighter-rouge">--ignore_subject_consistency</code> flags; outputs identical to Iteration 1.2 above (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/validator_parser.ipynb">validator_parser.ipynb</a>).<li>Reran <code class="language-plaintext highlighter-rouge">cubids-group</code> - still resulted in 23 acquisition groups, including addition of 4 new KeyParamGroups (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>): acquisition-VARIANTNoFmap_datatype-func_run-2_suffix-bold_task-card acquisition-VARIANTNoFmap_datatype-func_run-2_suffix-bold_task-face acquisition-VARIANTNoFmap_datatype-func_run-1_suffix-bold_task-face acquisition-VARIANTObliquityNoFmap_datatype-func_suffix-bold_task-rest acquisition-VARIANTNoFmap_datatype-func_suffix-bold_task-rest<li>Groupings approved by Ted and Tinashe, ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> without modifications to iter2_summary or iter2_files: <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad BIDS code/iterations/iteration2/iter2_summary.csv code/iterations/iteration2/iter2_files.csv code/iterations/apply1</code><li><code class="language-plaintext highlighter-rouge">cubids-apply</code> created apply1_full_cmd.sh (renamed to apply1a_full_cmd.sh) but unsuccessful in renaming files; internet disconnected and wasn’t able to copy error from jupyter terminal, reran command and reproduced error: <code class="language-plaintext highlighter-rouge">raise CommandError( datalad.support.exceptions.CommandError: CommandError: 'bash code/iterations/apply1_full_cmd.sh' failed with exitcode 127 under /gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS'</code><li>decided to edit iter2_summary.csv and rerun per Tinashe’s request to rename lengthy T1w keygroups, then will try to solve cubids-apply error<ul><li>renamed:<ul><li>KeyParamGroup datatype-anat_suffix-T1w__3 to acquisition-VARIANTAllwithParallelReductionFactorInPlane_datatype-anat_suffix-T1w<li>KeyParamGroup datatype-anat_suffix-T1w__4 to acquisition-VARIANTAll_datatype-anat_suffix-T1w<br /> Ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> with above modifications to iter2_summary.csv: <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad BIDS code/iterations/iteration2/iter2_summary.csv code/iterations/iteration2/iter2_files.csv code/iterations/apply2</code></ul></ul></ul><li>Iteration 3<ul><li>per Sydney Covitz’s recommendations, reran <code class="language-plaintext highlighter-rouge">cubids-group using</code> full paths: <code class="language-plaintext highlighter-rouge">cubids-group --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration3/iter3</code><li>resulted in 23 acquisition groups, including addition of 4 new KeyParamGroups (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>): acquisition-VARIANTNumVolumesNoFmap_datatype-func_run-2_suffix-bold_task-face acquisition-VARIANTNumVolumesNoFmap_datatype-func_run-1_suffix-bold_task-face acquisition-VARIANTNumVolumesNoFmap_datatype-func_suffix-bold_task-rest acquisition-VARIANTNumVolumesNoFmap_datatype-func_suffix-bold_task-rest<li>reviewed with Sydney, discovered that prior <code class="language-plaintext highlighter-rouge">cubids-apply</code> attempts had succcessfully renamed IntendedFors field in fmap json’s but exited before being able to rename the filenames (due to the fact that the files.csv had the /gpfs/fs001/ string in it because cubids-group was run using relative paths), resulting in “NoFmap” additions above. Per Sydney’s recommendation running <code class="language-plaintext highlighter-rouge">cubids-undo</code> to un-rename IntendedFors; reran <code class="language-plaintext highlighter-rouge">cubids-group</code> and finally <code class="language-plaintext highlighter-rouge">cubids-apply</code> using abs. paths.<ul><li>ran <code class="language-plaintext highlighter-rouge">git clean -f -d</code> to remove untracked changes in .ipynb_checkpoints<li>ran <code class="language-plaintext highlighter-rouge">cubids-undo</code>, used <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/intendedfor_rename.ipynb">intendedfor_rename.ipynb</a> to verify once VARIANT renames had been cleared. Datalad executes undone tracked below:<ul><li>HEAD is now at 69e473c Renamed IntendedFors<li>HEAD is now at 1ccd650 Renamed IntendedFors<li>HEAD is now at c8466c7 Renamed IntendedFors<li>HEAD is now at abc67c1 Renamed IntendedFors<li>HEAD is now at 26b23ee Renamed IntendedFors<li>HEAD is now at edfb983 updating .ipynb</ul></ul></ul><li>Iteration 4<ul><li>successfully removed all VARIANT intendedfors, rerunning: <code class="language-plaintext highlighter-rouge">cubids-group --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4</code><li>reviewed groupings against iter2 using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>, no changes. Renamed the lengthy T1w keygroups per Tinashe’s request:<ul><li>datatype-anat_suffix-T1w__3 : acquisition-VARIANTAllwithParallelReductionFactorInPlane_datatype-anat_suffix-T1w<li>datatype-anat_suffix-T1w__4 : acquisition-VARIANTAll_datatype-anat_suffix-T1w</ul><li>ran: <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4_summary.csv /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4_files.csv /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply2</code><li><code class="language-plaintext highlighter-rouge">cubids-apply</code> successful<li>ran <code class="language-plaintext highlighter-rouge">cubids-validate</code>, no new errors or warnings: EVENTS_TSV_MISSING : 495 scans README_FILE_MISSING : 1 count NO_AUTHORS : 1 count</ul><li>Iteration 5<ul><li>3 exemplar subjects (sub-15546, sub-16181, &amp; sub-12235) failed running fmriprep due to abberant image shape (64, 64, 43) in fmap images. Each subject compromised a unique Acquisition group. Deleting all fmap images (listed using Dim3_err_fmaps.ipynb): <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/fmap_to_rm2.txt</code><li>ran <code class="language-plaintext highlighter-rouge">cubids-group</code>, new groups ID’d for above subj (NoFMap) that will be merged into existing NoFMap groups with <code class="language-plaintext highlighter-rouge">cubids-apply</code><li>ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> without changes with prefix apply3, successful<li>ran <code class="language-plaintext highlighter-rouge">cubids-validate</code>, parsed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/validator_parser.ipynb">validator_parser.ipynb</a>, no new errors or warnings: EVENTS_TSV_MISSING : 495 scans README_FILE_MISSING : 1 count NO_AUTHORS : 1 count</ul><li>Iteration 6<ul><li>3 subjects (sub-13373, sub-14858, sub-15709) failed fmriprep due to CRC error, deleting nifti files identified in log outputs: <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/CRC_err_to_rm.txt</code> *NOTE: these 3 scans can be rerun in the future with a different version of fmriprep that doesn’t have this gzip error!<li>ran <code class="language-plaintext highlighter-rouge">cubids-group</code>, no new variants (no RenameKeyGroups for non-fmap KeyGroups) - Tinashe reviewed, no need for <code class="language-plaintext highlighter-rouge">cubids-apply/validate</code></ul><li>Timing Files<ul><li>created event timing files (events.tsv) based on <code class="language-plaintext highlighter-rouge">K23_fmri_paradigm.xls</code> provided by Dan Wolf<ul><li>used stick files to create two .csv’s listing all events for run-1 (task A) and run-2 (task B) respectively (cardA and faceA have the same timings/outcome order, just the stimuli are different; cardB and faceB have the same timings/outcomes)<li><strong>ONSET TIMES IN STICK FILES REFLECT FACT THAT ANALYSIS PIPELINE DELETED FIRST 20 SECONDS=10TR OF BOLD RUNS, DURING WHICH TWO “DUMMY” TASK TRIALS OCCURRED</strong><li>converted to .tsv’s using <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/csv_to_tsv.ipynb">csv_to_tsv.ipynb</a></ul><li>copied .tsvs into Day2/curation/BIDS, reran <code class="language-plaintext highlighter-rouge">cubids-validate</code>; took several iterations of renaming events.tsv’s so they will be correctly applied/pass validator, succeded on iteration 5 (<code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/tsv5_validation.csv</code>)</ul></ul><h3 id="preprocessing-pipelines"> <a href="#preprocessing-pipelines" class="anchor-heading" aria-labelledby="preprocessing-pipelines"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Preprocessing Pipelines</h3><ul><li>fMRIPrep (version 20.2.3)<ul><li>Margaret Gardner is responsible for running preprocessing pipelines/audits on CUBIC<li>Exemplar Testing:<ul><li>ran <code class="language-plaintext highlighter-rouge">cubids-copy-exemplars --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_dir /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply2_AcqGrouping.csv</code><li>Path to exemplar dataset (annexed to datalad): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_dir</code><li>Path to fmriprep container (.sif copied from dropbox, annexed to datalad): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_test/fmriprep-container</code><li>ran <code class="language-plaintext highlighter-rouge">(tail -n 1 code/qsub_calls.sh)</code> w/out modifications to participant_job.sh or fmriprep_zip.sh but no output branch created and didn’t save job number; reran, job writing to analysis/logs but seems unable to create new datalad branch (<code class="language-plaintext highlighter-rouge">pushingitremote... line 32: datalad: command not found</code>); ** edited <code class="language-plaintext highlighter-rouge">participant_job.sh</code> to correct conda environment (from base to margaret_reward) and run job in /cbica/comp_space; failed b/c had comments in-line on <code class="language-plaintext highlighter-rouge">fmriprep_zip.sh</code> ** reviewed with Tinashe and edited <code class="language-plaintext highlighter-rouge">fmriprep_zip.sh</code>; reran job 1424461 (“fpsub-12583”) has been submitted - completed successfully ** ran <code class="language-plaintext highlighter-rouge">bash code/qsub_calls.sh</code>, submitted jobs 1679260 through 1679282 &amp; merged to merge_ds (with help from Sydney &amp; Matt - issues with merge failing since test sub-12583 had already been merged, followed their instruction to delete both sub-12583 branches since .zip files already present in merge_ds)<li>error in sub-15546, sub-16181, &amp; sub-12235 (fmap images with Dim3Size=43, unable to construct fmaps - removing all fmap images for these subjects, see <strong>Iteration 5</strong> above) *Note: flag <code class="language-plaintext highlighter-rouge">--use-syn-sdc</code> not included in fmriprep run call, so no susceptibility distortion correction was run for subjects without fieldmaps<li>sub-12583 (test sub) doesn’t have branch in output_ria but is fine in audit<ul><li>Path to exemplar outputs: /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/fmriprep/output_ria <strong>testing dir deleted to save space on CUBIC on 12/2/21, once production completed</strong></ul></ul><li>Production Testing:<ul><li>ran <code class="language-plaintext highlighter-rouge">qsub_calls.sh</code>, submitted jobs 1831777 through 1831903<li>only 84 files in logfile, 123 branches created under output_ria<ul><li>running <code class="language-plaintext highlighter-rouge">merge_outputs.sh</code> and fmriprep-audit to identify failed subj<li>edited <code class="language-plaintext highlighter-rouge">concat_outputs.sh</code>(still old version on github) to pull tinashe’s new <a href="https://raw.githubusercontent.com/PennLINC/RBC/TinasheMTapera-fix-concatenator/PennLINC/Generic/concatenator.py"><code class="language-plaintext highlighter-rouge">concatenator.py</code> edits</a> and edited line 12 ‘concat_ds/csvs’ to ‘csvs’</ul><li>reviewed <code class="language-plaintext highlighter-rouge">FMRIPREP_AUDIT.csv</code>, 4 subj failed:<ul><li>sub-13373 - nipype.workflow ERROR: Node bold_to_std_transform.a0 failed to run on host 2119fmn002… File “indexed_gzip/indexed_gzip.pyx”, line 635, in indexed_gzip.indexed_gzip._IndexedGzipFile.seek indexed_gzip.indexed_gzip.CrcError: CRC/size validation failed - the GZIP data might be corrupt<ul><li>used <code class="language-plaintext highlighter-rouge">gzip -t -v</code> to validate CRC size for sub-13373_ses-day2_task-face_run-01_bold.nii.gz, OK</ul><li>sub-14858 - same as above, err on sub-14858_ses-day2_task-card_acq-VARIANTNoFmap_run-02_bold.nii.gz<li>sub-15709 - same as above, err on sub-15709_ses-day2_task-rest_bold.nii.gz<li>sub-17113 - no error message, log o and e incomplete - to rerun<li>removing scans with CRC error, see <strong>Iteration 6</strong> above - pushed BIDS updates to input_ria, rerunning qsub calls for sub-13373 (job 1974456), sub-14858 (job 1974459), sub-15709 (job 1974460), and sub-17113 (job 1974462); ran successfully based on logs, deleted merge_ds and reran <code class="language-plaintext highlighter-rouge">merge_outputs.sh</code>. Regot and reran fmriprep-audit</ul><li>all 125 subjecs successfully processed<li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS</code><li>Path to fmriprep run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/analysis/code/fmriprep_zip.sh</code><li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/output_ria</code><li>Path to fmriprep production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep-audit/FMRIPREP_AUDIT.csv</code><li>Path to freesurfer production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/freesurfer-audit</code> ** plotted Euler numbers generated by freesurfer_audit and plotted distribution. Sub-15433 recommended to be excluded from subsequent analyses (Euler=782). Reviewed sub-11305 (238) and sub-11399 (224) with Ted but ok’d</ul></ul><li>xcp-abcd<ul><li>Production Testing:<ul><li>edited participant_job.sh, xcp_zip.sh to update python environment, update “xcp-abcd-0-0-4” to “xcp-abcd-0-0-8” (matching container name and Tinashe’s scripts for other Reward projects)<li>ran test subject job 203853 (“xcpsub-17838”), successful!<li>submitted remaining jobs, successful!<li>submitted qsub_calls.sh for xcp-audit<li>wget and running bootstrap-quickunzip.sh to clone/unzip xcp outputs to xcp-derivatives; something didn’t work, seemed to overwrite unzip.sh?<ul><li>removed and wgot again, but had typo in path to xcp dir, rerunning with corrected path: <code class="language-plaintext highlighter-rouge">qsub -cwd -N "d2_unzip" bootstrap-quickunzip.sh /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp</code> - job 213392 (“d2_unzip”) has been submitted; job didn’t seem to run, no outputs; see e and o output files. Rerunning from terminal (not qsub-ed), renamed dir <code class="language-plaintext highlighter-rouge">wolf_satterthwaite_reward</code> to <code class="language-plaintext highlighter-rouge">derivatives-unzipped</code><li>concatenated <code class="language-plaintext highlighter-rouge">*space-MNI152NLin6Asym_desc-qc_res-2_bold.csv</code> outputs with <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/xcp_qc_concat.ipynb">xcp_qc_concat.ipynb</a>, plotted and saved outputs to github dir qc_plots</ul><li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/merge_ds</code><li>Path to xcp run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/analysis/code/xcp_zip.sh</code><li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/output_ria</code><li>Path to xcp production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp-audit/XCP_AUDIT.csv</code><li>Path to xcp derivatives: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/derivatives-unzipped/DERIVATIVES/XCP</code><li>Path to xcp derivatives (concatenated): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/qc_d2.csv</code></ul></ul></ul><h3 id="post-processing"> <a href="#post-processing" class="anchor-heading" aria-labelledby="post-processing"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Post Processing</h3><ul><li>Who is using the data/for which projects are people in the lab using this data?<ul><li>Link to project page(s) here</ul><li>For each post-processing analysis that has been run on this data, fill out the following<ul><li>Who performed the analysis?<li>Where it was performed (CUBIC, PMACS, somewhere else)?<li>GitHub Link(s) to result(s)<li>Did you use pennlinckit?<ul><li>https://github.com/PennLINC/PennLINC-Kit/tree/main/pennlinckit</ul></ul><li>FEAT task analysis<ul><li>fun side-quest for personal growth run by Margaret Gardner on CUBIC<li>wrote .txt timing files using <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl_timing_create.sh">fsl_timing_create.sh</a><li>Dan provided original feat analysis files for reference, saved under <code class="language-plaintext highlighter-rouge">fsl_sandbox/dan_orig</code><ul><li>“the events folder has all the stickfiles, lots of different variations. the feat directory has a feat directory for this control participant’s cardA analysis: 11242_03360; the nifti images is that persons 4D bold timeseries used for that feat analysis.”</ul><li>running on raw data from 3 subj randomly selected from Acquisition Group 1 (sub-16291, sub-15732, &amp; sub-15761) in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox</code> to familiarize with fsl workflow before adapting to accomodate fmriprep outputs; scripts run from git repo directory <code class="language-plaintext highlighter-rouge">fsl</code><ul><li>ran BET on sub-15732 with default settings, pial surface not fully removed - reran with f=0.7 but removed too much, sticking with default f=0.5<li>running FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0<ul><li>error in Registration: Could not find a supported file with prefix “/gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox/BIDS/card_run-01.feat/example_func.nii.gz”<li>talked to Greer and discovered error was in bet outputting .hdr/.imgs instead of .nii.gz - need to define FSLOUTPUTTYPE=NIFTI_GZ. Removed all fsl outputs/reverting to raw BIDs to run again</ul><li>ran BET on sub-15732 with default settings (-f 0.5), extraction looks good<li>ran FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0; successful,<li>ran Stats on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1)<li>running full analyses on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1); successful, removed old feat directories (preprocessing/stats only)<li>duplicating/editing design.fsf to github, create seperate design.fsf’s for each task/run combo (starting with card1, potentially iterate across card/task in the future since they have identical EVs)<li>testing <code class="language-plaintext highlighter-rouge">design_card1.fsf</code> on sub-16291, ran successfully<li>created design files for each task/run and updated <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a><li>ran <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a> <em>note: outputs and QCs not reviewed since this was for an exercise - would review and/or rerun if intending to use outputs in the future</em><ul><li>removed sub-16291/card1+.feat dir</ul><li>running 2nd level fixed-effects for card task (averaged across run 1 and 2 for each subj), output to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_2ndLevel.gfeat</code><li>running 3rd level FLAME 1 model for card cope 3 (win-lose), default thresholds (cluster z=3.1, p=0.05); inputs ``fsl_sandbox/card_2ndLevel.gfeat/cope3.feat/stats/cope?.nii.gz<code class="language-plaintext highlighter-rouge">; output to </code>fsl_sandbox/card_3rdLevel_win-lose.gfeat`<ul><li>also ran uncorrected analysis to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_3rdLevel_win-lose_uncorr.gfeat</code> just for fun</ul></ul></ul></ul><h3 id="to-do"> <a href="#to-do" class="anchor-heading" aria-labelledby="to-do"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> To Do</h3><ul><li>backup to PMACS<li>rename task entity (1 and 2 vs A and B)<li>script group level task analyses in FEAT<li>bootstrap FEAT analyses for datalad<li>adapt feat script to accept fmriprep outputs</ul><hr><footer><p><a href="#top" id="back-to-top">Back to top</a></p><p class="text-small text-grey-dk-100 mb-0">Copyright &copy; 2022 Ted Satterthwaite. Distributed by an <a href="https://github.com/PennLINC/Reward/blob/master/LICENSE.txt">MIT license.</a></p><div class="d-flex mt-2"></div></footer></div></div><div class="search-overlay"></div></div>
