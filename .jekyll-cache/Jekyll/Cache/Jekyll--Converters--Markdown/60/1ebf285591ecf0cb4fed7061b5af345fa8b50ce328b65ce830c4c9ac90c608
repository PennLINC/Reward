I"ÄK<h1 class="no_toc" id="fndm1">FNDM1</h1>

<details open="">
  <summary class="text-delta">
    Table of contents
  </summary>
<ol id="markdown-toc">
  <li><a href="#data-processing-flow--important-links" id="markdown-toc-data-processing-flow--important-links">Data Processing Flow &amp; Important Links:</a></li>
  <li><a href="#plan-for-the-data" id="markdown-toc-plan-for-the-data">Plan for the Data</a></li>
  <li><a href="#data-acquisition" id="markdown-toc-data-acquisition">Data Acquisition</a>    <ol>
      <li><a href="#download-and-storage" id="markdown-toc-download-and-storage">Download and Storage</a></li>
      <li><a href="#curation-process" id="markdown-toc-curation-process">Curation Process</a>        <ol>
          <li><a href="#bids-validation" id="markdown-toc-bids-validation">BIDS Validation:</a></li>
          <li><a href="#bids-optimization" id="markdown-toc-bids-optimization">BIDS Optimization:</a></li>
        </ol>
      </li>
      <li><a href="#preprocessing-pipelines" id="markdown-toc-preprocessing-pipelines">Preprocessing Pipelines</a></li>
      <li><a href="#post-processing" id="markdown-toc-post-processing">Post Processing</a></li>
      <li><a href="#to-do" id="markdown-toc-to-do">To Do</a></li>
    </ol>
  </li>
</ol>

</details>

<h1 id="data-processing-flow--important-links">Data Processing Flow &amp; Important Links:</h1>
<ul>
  <li>Flow diagram that describes the lifecycle of this dataset curation and preprocessing:</li>
</ul>

<p><img src="../DataProcessingFlow_fndm1.drawio.svg" alt="flow" /></p>

<ul>
  <li><strong>Overview:</strong>
    <ul>
      <li>subjects without usable fmaps (no SDC run in fMRIPrep): ‚Äòsub-12235‚Äô ‚Äòsub-13585‚Äô ‚Äòsub-14610‚Äô ‚Äòsub-14848‚Äô ‚Äòsub-14858‚Äô ‚Äòsub-14876‚Äô ‚Äòsub-15546‚Äô ‚Äòsub-16181‚Äô ‚Äòsub-16234‚Äô ‚Äòsub-17726‚Äô
  *scans noted <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/NoFmaps.ipynb">here</a></li>
      <li>subjects/scans that failed fMRIPrep: sub-13373_ses-day2_task-face_run-01_bold.nii.gz, sub-14858_ses-day2_task-card_run-02_bold.nii.gz, sub-15709_ses-day2_task-rest_bold.nii.gz
  <em>note: gzip error, can be rerun with later version</em></li>
      <li>subjects/scans with poor QC: sub-15433 T1w (euler=782); sub-17378 card1, card2, face1, face2 (normCrossCorr &lt;0.8); sub-15276 face2 (normCrossCorr &lt;0.8); sub-15433 card 2 (normCrossCorr &lt;0.8); 
  <em>note: paths to XCP-generated .html reports for each subject and concatenated qc values provided below</em></li>
    </ul>
  </li>
  <li>DSR GitHub Project Page(Curation/Validation and Processing Queue Status):</li>
</ul>

<p><a href="https://github.com/PennLINC/Reward/projects/1">https://github.com/PennLINC/Reward/projects/1</a></p>

<h1 id="plan-for-the-data">Plan for the Data</h1>

<ul>
  <li>Why does PennLINC need this data?
    <blockquote>
      <p>Acquired at UPenn</p>
    </blockquote>
  </li>
  <li>For which project(s) is it intended? Please link to project pages below:
    <blockquote>
      <p><a href="https://github.com/PennLINC/Reward/">Reward Project</a></p>
    </blockquote>
  </li>
  <li>Goal:
    <blockquote>
      <p>Curate and preprocess an amalgam of datasets for a harmonized PennLINC resource</p>
    </blockquote>
  </li>
</ul>

<h1 id="data-acquisition">Data Acquisition</h1>

<ul>
  <li>Data acquired by Dan Wolf &amp; Ted Satterthwaite</li>
  <li>Describe the data:
    <ul>
      <li>number of subjects = 56</li>
      <li>types of images = bold (2 runs task-CARD, 2 runs task-FACE, rest), T1w, fieldmaps</li>
    </ul>
  </li>
</ul>

<h3 id="download-and-storage">Download and Storage</h3>

<ul>
  <li>Original data available on Flywheel</li>
  <li>Source data (NIfTI) on CUBIC in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/original_data/bidsdatasets/fndm1</code>.</li>
  <li>Data was copied to <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/bidsdatasets/fndm1</code> and checked in to <code class="language-plaintext highlighter-rouge">datalad</code> after removing PHI (below)</li>
  <li>
    <p>JSON‚Äôs within origial_data were updated using <code class="language-plaintext highlighter-rouge">cubids-add-nifti-info</code>.</p>
  </li>
  <li>Listing metadata fields using <code class="language-plaintext highlighter-rouge">cubids-print-metadata-fields</code> gave the following fields:</li>
</ul>

<p>Acknowledgements
AcquisitionDateTime
AcquisitionMatrixPE
AcquisitionNumber
AcquisitionTime
Authors
BIDSVersion
BandwidthPerPixelPhaseEncode
BaseResolution
CoilString
ConversionSoftware
ConversionSoftwareVersion
DatasetDOI
DeidentificationMethod
DerivedVendorReportedEchoSpacing
DeviceSerialNumber
DwellTime
EchoNumber
EchoTime
EchoTime1
EchoTime2
EchoTrainLength
EffectiveEchoSpacing
FlipAngle
Funding
HowToAcknowledge
ImageOrientationPatientDICOM
ImageType
ImagingFrequency
InPlanePhaseEncodingDirectionDICOM
InstitutionAddress
InstitutionName
InstitutionalDepartmentName
IntendedFor
InversionTime
License
MRAcquisitionType
MagneticFieldStrength
Manufacturer
ManufacturersModelName
Modality
Name
ParallelReductionFactorInPlane
PartialFourier
PatientPosition
PatientSex
PercentPhaseFOV
PhaseEncodingDirection
PhaseEncodingSteps
PhaseResolution
PixelBandwidth
ProcedureStepDescription
ProtocolName
PulseSequenceDetails
ReceiveCoilName
ReconMatrixPE
RefLinesPE
ReferencesAndLinks
RepetitionTime
SAR
ScanOptions
ScanningSequence
SequenceName
SequenceVariant
SeriesDescription
SeriesInstanceUID
SeriesNumber
ShimSetting
SliceThickness
SliceTiming
SoftwareVersions
SpacingBetweenSlices
StationName
StudyID
StudyInstanceUID
TaskName
TotalReadoutTime
TxRefAmp
template
ImageComments
MultibandAccelerationFactor</p>

<p>Offending fields were removed with <code class="language-plaintext highlighter-rouge">cubids-remove-metadata-fields</code> in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/metadatafields_remove.sh</code></p>

<h3 id="curation-process">Curation Process</h3>

<ul>
  <li>Data curation by Tinashe Tapera on the CUBIC project user <code class="language-plaintext highlighter-rouge">wolfsatterthwaitereward</code></li>
  <li>Link to final CuBIDS csvs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/iterations/iteration7/fndm1/</code></li>
</ul>

<h4 id="bids-validation">BIDS Validation:</h4>

<ul>
  <li>
    <p>Data with short bold time series (&lt;3mins) were removed with the Notebook <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/RemoveShortBOLD.ipynb</code></p>
  </li>
  <li>
    <p>All validation outputs are available in chronological order in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/validate_outputs/fndm1</code>; most recent validation errors being:</p>
  </li>
  <li>
    <p>EVENTS_TSV_MISSING ( Task scans should have a corresponding events.tsv file. If this is a resting state scan you can ignore this warning or rename the task to include the word ‚Äúrest‚Äù. ) : 224 counts</p>
  </li>
  <li>
    <p>README_FILE_MISSING ( The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. ) : 1 count</p>
  </li>
  <li>
    <p>NO_AUTHORS ( The Authors field of dataset_description.json should contain an array of fields - with one author per field. This was triggered because there are no authors, which will make DOI registration from dataset metadata impossible. ) : 1 count</p>
  </li>
</ul>

<p>Data at this stage were approved for preprocessing.</p>

<h4 id="bids-optimization">BIDS Optimization:</h4>

<ul>
  <li>
    <p>All cubids optimization results are available in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/iterations/iter&lt;ITERATION_NUMBER&gt;/fndm1/</code></p>
  </li>
  <li>
    <p>Final optimization resulted in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/iterations/iter7/fndm1/fndm1_summary.csv</code></p>
  </li>
</ul>

<h3 id="preprocessing-pipelines">Preprocessing Pipelines</h3>

<ul>
  <li>fMRIPrep (version 20.2.3)
    <ul>
      <li>Tinashe Tapera was responsible for running preprocessing pipelines/audits on CUBIC</li>
      <li>Exemplar Testing:
        <ul>
          <li>Used cubids to create exemplar dataset: <code class="language-plaintext highlighter-rouge">cubids-copy-exemplars /cbica/projects/wolf_satterthwaite_reward/Curation/bidsdatasets/fndm1/BIDS /cbica/projects/wolf_satterthwaite_reward/Testing/fndm1/exemplars_dir /cbica/projects/wolf_satterthwaite_reward/Curation/code/iterations/iter7/fndm1/fndm1_AcqGrouping.csv</code></li>
          <li>Path to exemplar dataset (annexed to datalad): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Testing/fndm1/exemplars_dir</code></li>
          <li>Path to fmriprep container: Original in <code class="language-plaintext highlighter-rouge">~/dropbox</code>, datalad in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Testing/exemplars_test/fmriprep-container</code></li>
        </ul>
      </li>
      <li>Adjustments:
        <ul>
          <li>During testing, some fieldmaps were found to be corrupt/unusable for the data, and were removed. These files are in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Curation/code/iterations/cubids-testing_adjustments/fndm1/purge_broken_fmaps.txt</code></li>
        </ul>
      </li>
    </ul>

    <p><strong>testing dir deleted to save space on CUBIC on 12/2/21, once production completed</strong></p>

    <ul>
      <li>Production Testing:
        <ul>
          <li>all 125 subjecs successfully processed</li>
          <li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS</code></li>
          <li>Path to fmriprep run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/analysis/code/fmriprep_zip.sh</code></li>
          <li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/output_ria</code></li>
          <li>Path to fmriprep production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep-audit/FMRIPREP_AUDIT.csv</code></li>
          <li>Path to freesurfer production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/freesurfer-audit</code>
  ** plotted Euler numbers generated by freesurfer_audit and plotted distribution. Sub-15433 recommended to be excluded from subsequent analyses (Euler=782). Reviewed sub-11305 (238) and sub-11399 (224) with Ted but ok‚Äôd</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>xcp-abcd
    <ul>
      <li>Production Testing:
        <ul>
          <li>edited participant_job.sh, xcp_zip.sh to update python environment, update ‚Äúxcp-abcd-0-0-4‚Äù to ‚Äúxcp-abcd-0-0-8‚Äù (matching container name and Tinashe‚Äôs scripts for other Reward projects)</li>
          <li>ran test subject job 203853 (‚Äúxcpsub-17838‚Äù), successful!</li>
          <li>submitted remaining jobs, successful!</li>
          <li>submitted qsub_calls.sh for xcp-audit</li>
          <li>wget and running bootstrap-quickunzip.sh to clone/unzip xcp outputs to xcp-derivatives; something didn‚Äôt work, seemed to overwrite unzip.sh?
            <ul>
              <li>removed and wgot again, but had typo in path to xcp dir, rerunning with corrected path: <code class="language-plaintext highlighter-rouge">qsub -cwd -N "d2_unzip" bootstrap-quickunzip.sh /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp</code> - job 213392 (‚Äúd2_unzip‚Äù) has been submitted; job didn‚Äôt seem to run, no outputs; see e and o output files. Rerunning from terminal (not qsub-ed), renamed dir <code class="language-plaintext highlighter-rouge">wolf_satterthwaite_reward</code> to <code class="language-plaintext highlighter-rouge">derivatives-unzipped</code></li>
              <li>concatenated <code class="language-plaintext highlighter-rouge">*space-MNI152NLin6Asym_desc-qc_res-2_bold.csv</code> outputs with <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/xcp_qc_concat.ipynb">xcp_qc_concat.ipynb</a>, plotted and saved outputs to github dir qc_plots</li>
            </ul>
          </li>
          <li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/merge_ds</code></li>
          <li>Path to xcp run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/analysis/code/xcp_zip.sh</code></li>
          <li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/output_ria</code></li>
          <li>Path to xcp production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp-audit/XCP_AUDIT.csv</code></li>
          <li>Path to xcp derivatives: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/derivatives-unzipped/DERIVATIVES/XCP</code></li>
          <li>Path to xcp derivatives (concatenated): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/qc_d2.csv</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="post-processing">Post Processing</h3>

<ul>
  <li>Who is using the data/for which projects are people in the lab using this data?
    <ul>
      <li>Link to project page(s) here</li>
    </ul>
  </li>
  <li>For each post-processing analysis that has been run on this data, fill out the following
    <ul>
      <li>Who performed the analysis?</li>
      <li>Where it was performed (CUBIC, PMACS, somewhere else)?</li>
      <li>GitHub Link(s) to result(s)</li>
      <li>Did you use pennlinckit?
        <ul>
          <li>https://github.com/PennLINC/PennLINC-Kit/tree/main/pennlinckit</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>FEAT task analysis
    <ul>
      <li>fun side-quest for personal growth run by Margaret Gardner on CUBIC</li>
      <li>wrote .txt timing files using <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl_timing_create.sh">fsl_timing_create.sh</a></li>
      <li>Dan provided original feat analysis files for reference, saved under <code class="language-plaintext highlighter-rouge">fsl_sandbox/dan_orig</code>
        <ul>
          <li>‚Äúthe events folder has all the stickfiles, lots of different variations. the feat directory has a feat directory for this control participant‚Äôs cardA analysis: 11242_03360; the nifti images is that persons 4D bold timeseries used for that feat analysis.‚Äù</li>
        </ul>
      </li>
      <li>running on raw data from 3 subj randomly selected from Acquisition Group 1 (sub-16291, sub-15732, &amp; sub-15761) in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox</code> to familiarize with fsl workflow before adapting to accomodate fmriprep outputs; scripts run from git repo directory <code class="language-plaintext highlighter-rouge">fsl</code>
        <ul>
          <li>ran BET on sub-15732 with default settings, pial surface not fully removed - reran with f=0.7 but removed too much, sticking with default f=0.5</li>
          <li>running FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0
            <ul>
              <li>error in Registration: Could not find a supported file with prefix ‚Äú/gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox/BIDS/card_run-01.feat/example_func.nii.gz‚Äù</li>
              <li>talked to Greer and discovered error was in bet outputting .hdr/.imgs instead of .nii.gz - need to define FSLOUTPUTTYPE=NIFTI_GZ. Removed all fsl outputs/reverting to raw BIDs to run again</li>
            </ul>
          </li>
          <li>ran BET on sub-15732 with default settings (-f 0.5), extraction looks good</li>
          <li>ran FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0; successful,</li>
          <li>ran Stats on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1)</li>
          <li>running full analyses on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1); successful, removed old feat directories (preprocessing/stats only)</li>
          <li>duplicating/editing design.fsf to github, create seperate design.fsf‚Äôs for each task/run combo (starting with card1, potentially iterate across card/task in the future since they have identical EVs)</li>
          <li>testing <code class="language-plaintext highlighter-rouge">design_card1.fsf</code> on sub-16291, ran successfully</li>
          <li>created design files for each task/run and updated <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a></li>
          <li>ran <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a> <em>note: outputs and QCs not reviewed since this was for an exercise - would review and/or rerun if intending to use outputs in the future</em>
            <ul>
              <li>removed sub-16291/card1+.feat dir</li>
            </ul>
          </li>
          <li>running 2nd level fixed-effects for card task (averaged across run 1 and 2 for each subj), output to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_2ndLevel.gfeat</code></li>
          <li>running 3rd level FLAME 1 model for card cope 3 (win-lose), default thresholds (cluster z=3.1, p=0.05);  inputs ``fsl_sandbox/card_2ndLevel.gfeat/cope3.feat/stats/cope?.nii.gz<code class="language-plaintext highlighter-rouge">; output to </code>fsl_sandbox/card_3rdLevel_win-lose.gfeat`
            <ul>
              <li>also ran uncorrected analysis to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_3rdLevel_win-lose_uncorr.gfeat</code> just for fun</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="to-do">To Do</h3>
<ul>
  <li>backup to PMACS</li>
  <li>rename task entity (1 and 2 vs A and B)</li>
  <li>script group level task analyses in FEAT</li>
  <li>bootstrap FEAT analyses for datalad</li>
  <li>adapt feat script to accept fmriprep outputs</li>
</ul>
:ET