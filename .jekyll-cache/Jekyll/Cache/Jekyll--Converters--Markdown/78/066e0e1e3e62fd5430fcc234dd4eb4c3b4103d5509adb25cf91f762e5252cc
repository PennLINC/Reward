I"ô<h2 id="data-narrative-for-day2---margarets-curation">Data Narrative for DAY2 - Margaret‚Äôs Curation</h2>

<h3 id="data-processing-flow--important-links">Data Processing Flow &amp; Important Links:</h3>
<ul>
  <li>Flow diagram that describes the lifecycle of this dataset curation and preprocessing may be viewed <a href="https://github.com/PennLINC/DAY2_Margaret/blob/c45c9e9e6a7837f698f430677cf323aca0395f5e/Day2%20Project%20Update.pdf">here</a></li>
  <li><strong>Overview:</strong>
    <ul>
      <li>subjects without usable fmaps (no SDC run in fMRIPrep): ‚Äòsub-12235‚Äô ‚Äòsub-13585‚Äô ‚Äòsub-14610‚Äô ‚Äòsub-14848‚Äô ‚Äòsub-14858‚Äô ‚Äòsub-14876‚Äô ‚Äòsub-15546‚Äô ‚Äòsub-16181‚Äô ‚Äòsub-16234‚Äô ‚Äòsub-17726‚Äô
  *scans noted <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/NoFmaps.ipynb">here</a></li>
      <li>subjects/scans that failed fMRIPrep: sub-13373_ses-day2_task-face_run-01_bold.nii.gz, sub-14858_ses-day2_task-card_run-02_bold.nii.gz, sub-15709_ses-day2_task-rest_bold.nii.gz
  <em>note: gzip error, can be rerun with later version</em></li>
      <li>subjects/scans with poor QC: sub-15433 T1w (euler=782); sub-17378 card1, card2, face1, face2 (normCrossCorr &lt;0.8); sub-15276 face2 (normCrossCorr &lt;0.8); sub-15433 card 2 (normCrossCorr &lt;0.8); 
  <em>note: paths to XCP-generated .html reports for each subject and concatenated qc values provided below</em></li>
    </ul>
  </li>
  <li>DSR GitHub Project Page(Curation/Validation and Processing Queue Status):
    <ul>
      <li>Cards for tracking the curation and validation portion of the dataset. This page should be updated every time you perform an action on the data.</li>
      <li>Cards for tracking the progress of containerized pipeline runs on the data.</li>
    </ul>
  </li>
</ul>

<h3 id="plan-for-the-data">Plan for the Data</h3>

<ul>
  <li>Why does PennLINC need this data?</li>
  <li>For which project(s) is it intended? Please link to project pages below:</li>
  <li>Goal is to curate and preprocess data</li>
</ul>

<h3 id="data-acquisition">Data Acquisition</h3>

<ul>
  <li>Data acquired by Dan Wolf</li>
  <li>Describe the data:
    <ul>
      <li>number of subjects = 125</li>
      <li>types of images = bold (2 runs task-face, 2 runs task-card, rest), T1w, T2w, DWI
 <em>note: run1=task version A and run2 = task version B according to json SeriesDescription, see <a href="https://github.com/PennLINC/DAY2_Margaret/blob/f35fb7bdb2422b72d42d9328dd5644e7b5ddba12/notebooks/task-match.ipynb">task-match.ipynb</a></em>
        <ul>
          <li>T1w = 125 subj</li>
          <li>T2w = 3 subj</li>
          <li>card_run-01 = 124 subj</li>
          <li>card_run-02 = 124 subj</li>
          <li>face_run-01 = 123 subj</li>
          <li>face_run-02 = 124 subj</li>
          <li>rest = 114 subj</li>
          <li>fmap = 124 subj</li>
          <li>dwi = 3 subj</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="download-and-storage">Download and Storage</h3>

<ul>
  <li>Data was stored as nifti files in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/original_data/bidsdatasets/day2</code>.</li>
  <li>Data was copied by Margaret to sub-project folder <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/original_data</code> on 9/14/2021.</li>
  <li>
    <p>JSON‚Äôs within origial_data were updated using <code class="language-plaintext highlighter-rouge">cubids-add-nifti-info</code>.</p>
  </li>
  <li>Listing metadata fields using <code class="language-plaintext highlighter-rouge">cubids-print-metadata-fields</code> resulted:
    <ul>
      <li>Acknowledgements</li>
      <li>AcquisitionMatrixPE</li>
      <li>AcquisitionNumber</li>
      <li>Authors</li>
      <li>BIDSVersion</li>
      <li>BandwidthPerPixelPhaseEncode</li>
      <li>BaseResolution</li>
      <li>CoilString</li>
      <li>ConversionSoftware</li>
      <li>ConversionSoftwareVersion</li>
      <li>DatasetDOI</li>
      <li>DeidentificationMethod</li>
      <li>DerivedVendorReportedEchoSpacing</li>
      <li>DeviceSerialNumber</li>
      <li>Dim1Size</li>
      <li>Dim2Size</li>
      <li>Dim3Size</li>
      <li>DwellTime</li>
      <li>EchoNumber</li>
      <li>EchoTime</li>
      <li>EchoTime1</li>
      <li>EchoTime2</li>
      <li>EchoTrainLength</li>
      <li>EffectiveEchoSpacing</li>
      <li>FlipAngle</li>
      <li>Funding</li>
      <li>HowToAcknowledge</li>
      <li>ImageOrientationPatientDICOM</li>
      <li>ImageType</li>
      <li>ImagingFrequency</li>
      <li>InPlanePhaseEncodingDirectionDICOM</li>
      <li>IntendedFor</li>
      <li>InversionTime</li>
      <li>License</li>
      <li>MRAcquisitionType</li>
      <li>MagneticFieldStrength</li>
      <li>Manufacturer</li>
      <li>ManufacturersModelName</li>
      <li>Modality</li>
      <li>Name</li>
      <li>NumVolumes</li>
      <li>Obliquity</li>
      <li>ParallelReductionFactorInPlane</li>
      <li>PartialFourier</li>
      <li>PercentPhaseFOV</li>
      <li>PhaseEncodingDirection</li>
      <li>PhaseEncodingSteps</li>
      <li>PhaseResolution</li>
      <li>PixelBandwidth</li>
      <li>ProcedureStepDescription</li>
      <li>ProtocolName</li>
      <li>PulseSequenceDetails</li>
      <li>ReceiveCoilName</li>
      <li>ReconMatrixPE</li>
      <li>RefLinesPE</li>
      <li>ReferencesAndLinks</li>
      <li>RepetitionTime</li>
      <li>SAR</li>
      <li>ScanOptions</li>
      <li>ScanningSequence</li>
      <li>SequenceName</li>
      <li>SequenceVariant</li>
      <li>SeriesDescription</li>
      <li>SeriesInstanceUID</li>
      <li>SeriesNumber</li>
      <li>ShimSetting</li>
      <li>SliceThickness</li>
      <li>SliceTiming</li>
      <li>SoftwareVersions</li>
      <li>SpacingBetweenSlices</li>
      <li>TaskName</li>
      <li>TotalReadoutTime</li>
      <li>TxRefAmp</li>
      <li>VoxelSizeDim1</li>
      <li>VoxelSizeDim2</li>
      <li>VoxelSizeDim3</li>
      <li>template</li>
    </ul>

    <p>Running <code class="language-plaintext highlighter-rouge">cubids-remove-metadata-fields</code> resulted no PHI fields for removal.</p>
  </li>
  <li>Data checked into DataLad <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS (dataset)</code> via <code class="language-plaintext highlighter-rouge">datalad save -m "add initial data" -d ./curation/BIDS</code> 
  <code class="language-plaintext highlighter-rouge">action summary:                                                               
    add (ok: 2448)
    save (ok: 1)</code></li>
</ul>

<h3 id="curation-process">Curation Process</h3>

<ul>
  <li>Data curation by Margaret Gardner for NGG rotation on the CUBIC project user <code class="language-plaintext highlighter-rouge">wolfsatterthwaitereward</code></li>
  <li>Link to final CuBIDS csvs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration6</code></li>
</ul>

<h4 id="bids-validation">BIDS Validation:</h4>

<ul>
  <li>
    <p>Iteration 1 (Ran <code class="language-plaintext highlighter-rouge">cubids-validate</code> and <code class="language-plaintext highlighter-rouge">cubids-group</code> simultanously as per The WAY, outputs saved to <code class="language-plaintext highlighter-rouge">sandbox/validator_outputs/iteration1</code>):
  EVENTS_TSV_MISSING ( Task scans should have a corresponding events.tsv file. If this is a resting state scan you can ignore this warning or rename the task to include the word ‚Äúrest‚Äù. ) : 495 counts
  INCONSISTENT_SUBJECTS ( Not all subjects contain the same files. Each subject should contain the same number of files with the same naming unless some files are known to be missing. ) : 806 counts
  INCONSISTENT_PARAMETERS ( Not all subjects/sessions/runs have the same scanning parameters. ) : 24 subjects
  README_FILE_MISSING ( The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. ) : 1 subjects
  NO_AUTHORS ( The Authors field of dataset_description.json should contain an array of fields - with one author per field. This was triggered because there are no authors, which will make DOI registration from dataset metadata impossible. ) : 1 subjects</p>
  </li>
  <li>
    <p>Iteration 1.2 (Reran <code class="language-plaintext highlighter-rouge">cubids-validate</code> with <code class="language-plaintext highlighter-rouge">--ignore_nifti_headers</code> and <code class="language-plaintext highlighter-rouge">--ignore_subject_consistency</code>, no modifications to datafiles):
  EVENTS_TSV_MISSING ( Task scans should have a corresponding events.tsv file. If this is a resting state scan you can ignore this warning or rename the task to include the word ‚Äúrest‚Äù. ) : 495 scans
  README_FILE_MISSING ( The recommended file /README is missing. See Section 03 (Modality agnostic files) of the BIDS specification. ) : 1 count
  NO_AUTHORS ( The Authors field of dataset_description.json should contain an array of fields - with one author per field. This was triggered because there are no authors, which will make DOI registration from dataset metadata impossible. ) : 1 count</p>

    <p>*counts using  <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a></p>
  </li>
  <li>
    <p>BIDS curation approved by Ted Satterthwaite and Tinashe Tapera on 9/21/21, last validator output of original data available at <code class="language-plaintext highlighter-rouge">/gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/d2_r2_validation.csv</code>. Data backed up to datalad.</p>
  </li>
</ul>

<h4 id="bids-optimization">BIDS Optimization:</h4>

<p>*NOTE: any files removed from <code class="language-plaintext highlighter-rouge">curation/BIDS</code> dataset noted in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/curation_*_cmd.sh</code> scripts, which are written by <code class="language-plaintext highlighter-rouge">cubids-purge</code>. Any files renamed (Acquisition Variants) noted in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply*_cmd.sh</code> scripts, which are written by <code class="language-plaintext highlighter-rouge">cubids-apply</code>.</p>

<ul>
  <li>BIDs groups from Iteration 1.2 reviewed by Ted and Tinashe
    <ul>
      <li>reviewed subject files for duplicates, no subj with more than one T1w or each type of fmap (phase1, phase2, magnitude1, magnitude2)</li>
      <li>
        <ul>
          <li>118 subj have full set of phase1&amp;2, magnitude1&amp;2 files</li>
        </ul>
      </li>
      <li>
        <ul>
          <li>5 subj have only phasediff files (mislabeled phase1) but no magnitude files</li>
        </ul>
      </li>
      <li>
        <ul>
          <li>1 subj has only phase1 &amp; phase2 files but no magnitude files</li>
        </ul>
      </li>
      <li>identified 3 subjects who have T2 data (KeyParamGroup=datatype-anat_suffix-T2w__1) in addition to T1 that compromise AcqGroup 3</li>
      <li>Plan to add A/B designation task entity for files to disambiguate task version (cardA,cardB, faceA, or faceB) performed during each run. Data currently contained in SeriesDescription, see <a href="https://github.com/PennLINC/DAY2_Margaret/blob/f35fb7bdb2422b72d42d9328dd5644e7b5ddba12/notebooks/task-match.ipynb">task-match.ipynb</a>
  *counts using  <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a> *</li>
    </ul>
  </li>
  <li>Iteration 2
    <ul>
      <li>made sure all files in curation/BIDS checked into datalad</li>
      <li>T2 files to be removed written to code/sandbox/T2w.txt using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a>, ran <code class="language-plaintext highlighter-rouge">cubids-purge</code>:
 <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/T2w.txt</code></li>
      <li>fmap files to be removed written to <code class="language-plaintext highlighter-rouge">Margaret/Day2/curation/code/sandbox/validator_outputs/iteration1.2/fmap_to_rm.txt</code> using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/7691b7cb97d56dc9ddd864899c9fed82452a4a47/notebooks/validator_err_counts.ipynb">validator_err_counts.ipynb</a>, ran <code class="language-plaintext highlighter-rouge">cubids-purge</code>:
 <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/iteration1.2/fmap_to_rm.txt</code></li>
      <li>Reran <code class="language-plaintext highlighter-rouge">cubids-validator</code> iter2 with <code class="language-plaintext highlighter-rouge">--ignore_nifti_headers</code> and <code class="language-plaintext highlighter-rouge">--ignore_subject_consistency</code> flags; outputs identical to Iteration 1.2 above (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/validator_parser.ipynb">validator_parser.ipynb</a>).</li>
      <li>Reran <code class="language-plaintext highlighter-rouge">cubids-group</code> - still resulted in 23 acquisition groups, including addition of 4 new KeyParamGroups (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>):
  acquisition-VARIANTNoFmap_datatype-func_run-2_suffix-bold_task-card
  acquisition-VARIANTNoFmap_datatype-func_run-2_suffix-bold_task-face
  acquisition-VARIANTNoFmap_datatype-func_run-1_suffix-bold_task-face
  acquisition-VARIANTObliquityNoFmap_datatype-func_suffix-bold_task-rest
  acquisition-VARIANTNoFmap_datatype-func_suffix-bold_task-rest</li>
      <li>Groupings approved by Ted and Tinashe, ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> without modifications to iter2_summary or iter2_files:
 <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad BIDS code/iterations/iteration2/iter2_summary.csv code/iterations/iteration2/iter2_files.csv code/iterations/apply1</code></li>
      <li><code class="language-plaintext highlighter-rouge">cubids-apply</code> created apply1_full_cmd.sh (renamed to apply1a_full_cmd.sh) but unsuccessful in renaming files; internet disconnected and wasn‚Äôt able to copy error from jupyter terminal, reran command and reproduced error:
  <code class="language-plaintext highlighter-rouge">raise CommandError(
datalad.support.exceptions.CommandError: CommandError: 'bash code/iterations/apply1_full_cmd.sh' failed with exitcode 127 under /gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS'</code></li>
      <li>decided to edit iter2_summary.csv and rerun per Tinashe‚Äôs request to rename lengthy T1w keygroups, then will try to solve cubids-apply error
        <ul>
          <li>renamed:
            <ul>
              <li>KeyParamGroup datatype-anat_suffix-T1w__3 to acquisition-VARIANTAllwithParallelReductionFactorInPlane_datatype-anat_suffix-T1w</li>
              <li>KeyParamGroup datatype-anat_suffix-T1w__4 to acquisition-VARIANTAll_datatype-anat_suffix-T1w<br />
 Ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> with above modifications to iter2_summary.csv:
 <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad BIDS code/iterations/iteration2/iter2_summary.csv code/iterations/iteration2/iter2_files.csv code/iterations/apply2</code></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Iteration 3
    <ul>
      <li>per Sydney Covitz‚Äôs recommendations, reran <code class="language-plaintext highlighter-rouge">cubids-group using</code> full paths:
  <code class="language-plaintext highlighter-rouge">cubids-group --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration3/iter3</code></li>
      <li>resulted in 23 acquisition groups, including addition of 4 new KeyParamGroups (reviewed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>):
  acquisition-VARIANTNumVolumesNoFmap_datatype-func_run-2_suffix-bold_task-face
  acquisition-VARIANTNumVolumesNoFmap_datatype-func_run-1_suffix-bold_task-face
  acquisition-VARIANTNumVolumesNoFmap_datatype-func_suffix-bold_task-rest
  acquisition-VARIANTNumVolumesNoFmap_datatype-func_suffix-bold_task-rest</li>
      <li>reviewed with Sydney, discovered that prior <code class="language-plaintext highlighter-rouge">cubids-apply</code> attempts had succcessfully renamed IntendedFors field in fmap json‚Äôs but exited before being able to rename the filenames (due to the fact that the files.csv had the /gpfs/fs001/ string in it because cubids-group was run using relative paths), resulting in ‚ÄúNoFmap‚Äù additions above. Per Sydney‚Äôs recommendation running <code class="language-plaintext highlighter-rouge">cubids-undo</code> to un-rename IntendedFors; reran <code class="language-plaintext highlighter-rouge">cubids-group</code> and finally <code class="language-plaintext highlighter-rouge">cubids-apply</code> using abs. paths.
        <ul>
          <li>ran <code class="language-plaintext highlighter-rouge">git clean -f -d</code> to remove untracked changes in .ipynb_checkpoints</li>
          <li>ran <code class="language-plaintext highlighter-rouge">cubids-undo</code>, used <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/intendedfor_rename.ipynb">intendedfor_rename.ipynb</a> to verify once VARIANT renames had been cleared. Datalad executes undone tracked below:
            <ul>
              <li>HEAD is now at 69e473c Renamed IntendedFors</li>
              <li>HEAD is now at 1ccd650 Renamed IntendedFors</li>
              <li>HEAD is now at c8466c7 Renamed IntendedFors</li>
              <li>HEAD is now at abc67c1 Renamed IntendedFors</li>
              <li>HEAD is now at 26b23ee Renamed IntendedFors</li>
              <li>HEAD is now at edfb983 updating .ipynb</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Iteration 4
    <ul>
      <li>successfully removed all VARIANT intendedfors, rerunning:
 <code class="language-plaintext highlighter-rouge">cubids-group --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4</code></li>
      <li>reviewed groupings against iter2 using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/group_compare.ipynb">group_compare.ipynb</a>, no changes. Renamed the lengthy T1w keygroups per Tinashe‚Äôs request:
        <ul>
          <li>datatype-anat_suffix-T1w__3 : acquisition-VARIANTAllwithParallelReductionFactorInPlane_datatype-anat_suffix-T1w</li>
          <li>datatype-anat_suffix-T1w__4 : acquisition-VARIANTAll_datatype-anat_suffix-T1w</li>
        </ul>
      </li>
      <li>ran: <code class="language-plaintext highlighter-rouge">cubids-apply --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4_summary.csv /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/iteration4/iter4_files.csv /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply2</code></li>
      <li><code class="language-plaintext highlighter-rouge">cubids-apply</code> successful</li>
      <li>ran <code class="language-plaintext highlighter-rouge">cubids-validate</code>, no new errors or warnings:
  EVENTS_TSV_MISSING : 495 scans
  README_FILE_MISSING : 1 count
  NO_AUTHORS : 1 count</li>
    </ul>
  </li>
  <li>Iteration 5
    <ul>
      <li>3 exemplar subjects (sub-15546, sub-16181, &amp; sub-12235) failed running fmriprep due to abberant image shape (64, 64, 43) in fmap images. Each subject compromised a unique Acquisition group. Deleting all fmap images (listed using Dim3_err_fmaps.ipynb):
 <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/fmap_to_rm2.txt</code></li>
      <li>ran <code class="language-plaintext highlighter-rouge">cubids-group</code>, new groups ID‚Äôd for above subj (NoFMap) that will be merged into existing NoFMap groups with <code class="language-plaintext highlighter-rouge">cubids-apply</code></li>
      <li>ran <code class="language-plaintext highlighter-rouge">cubids-apply</code> without changes with prefix apply3, successful</li>
      <li>ran <code class="language-plaintext highlighter-rouge">cubids-validate</code>, parsed using <a href="https://github.com/PennLINC/DAY2_Margaret/blob/a3708a7c5f8559cb67f8aea83c7e853aed9afea0/notebooks/validator_parser.ipynb">validator_parser.ipynb</a>, no new errors or warnings:
  EVENTS_TSV_MISSING : 495 scans
  README_FILE_MISSING : 1 count
  NO_AUTHORS : 1 count</li>
    </ul>
  </li>
  <li>Iteration 6
    <ul>
      <li>3 subjects (sub-13373, sub-14858, sub-15709) failed fmriprep due to CRC error, deleting nifti files identified in log outputs:
 <code class="language-plaintext highlighter-rouge">cubids-purge --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/CRC_err_to_rm.txt</code>
  *NOTE: these 3 scans can be rerun in the future with a different version of fmriprep that doesn‚Äôt have this gzip error!</li>
      <li>ran <code class="language-plaintext highlighter-rouge">cubids-group</code>, no new variants (no RenameKeyGroups for non-fmap KeyGroups) - Tinashe reviewed, no need for <code class="language-plaintext highlighter-rouge">cubids-apply/validate</code></li>
    </ul>
  </li>
  <li>Timing Files
    <ul>
      <li>created event timing files (events.tsv) based on <code class="language-plaintext highlighter-rouge">K23_fmri_paradigm.xls</code> provided by Dan Wolf
        <ul>
          <li>used stick files to create two .csv‚Äôs listing all events for run-1 (task A) and run-2 (task B) respectively (cardA and faceA have the same timings/outcome order, just the stimuli are different; cardB and faceB have the same timings/outcomes)</li>
          <li><strong>ONSET TIMES IN STICK FILES REFLECT FACT THAT ANALYSIS PIPELINE DELETED FIRST 20 SECONDS=10TR OF BOLD RUNS, DURING WHICH TWO ‚ÄúDUMMY‚Äù TASK TRIALS OCCURRED</strong></li>
          <li>converted to .tsv‚Äôs using <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/csv_to_tsv.ipynb">csv_to_tsv.ipynb</a></li>
        </ul>
      </li>
      <li>copied .tsvs into Day2/curation/BIDS, reran <code class="language-plaintext highlighter-rouge">cubids-validate</code>; took several iterations of renaming events.tsv‚Äôs so they will be correctly applied/pass validator, succeded on iteration 5 (<code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/validator_outputs/tsv5_validation.csv</code>)</li>
    </ul>
  </li>
</ul>

<h3 id="preprocessing-pipelines">Preprocessing Pipelines</h3>

<ul>
  <li>fMRIPrep (version 20.2.3)
    <ul>
      <li>Margaret Gardner is responsible for running preprocessing pipelines/audits on CUBIC</li>
      <li>Exemplar Testing:
        <ul>
          <li>ran <code class="language-plaintext highlighter-rouge">cubids-copy-exemplars --use-datalad /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_dir /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/iterations/apply2_AcqGrouping.csv</code></li>
          <li>Path to exemplar dataset (annexed to datalad): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_dir</code></li>
          <li>Path to fmriprep container (.sif copied from dropbox, annexed to datalad): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/exemplars_test/fmriprep-container</code></li>
          <li>ran <code class="language-plaintext highlighter-rouge">(tail -n 1 code/qsub_calls.sh)</code> w/out modifications to participant_job.sh or fmriprep_zip.sh but no output branch created and didn‚Äôt save job number; reran, job writing to analysis/logs but seems unable to create new datalad branch (<code class="language-plaintext highlighter-rouge">pushingitremote... line 32: datalad: command not found</code>); 
  ** edited <code class="language-plaintext highlighter-rouge">participant_job.sh</code> to correct conda environment (from base to margaret_reward) and run job in /cbica/comp_space; failed b/c had comments in-line on <code class="language-plaintext highlighter-rouge">fmriprep_zip.sh</code>
  ** reviewed with Tinashe and edited <code class="language-plaintext highlighter-rouge">fmriprep_zip.sh</code>; reran job 1424461 (‚Äúfpsub-12583‚Äù) has been submitted - completed successfully
  ** ran <code class="language-plaintext highlighter-rouge">bash code/qsub_calls.sh</code>, submitted jobs 1679260 through 1679282 &amp; merged to merge_ds (with help from Sydney &amp; Matt - issues with merge failing since test sub-12583 had already been merged, followed their instruction to delete both sub-12583 branches since .zip files already present in merge_ds)</li>
          <li>error in sub-15546, sub-16181, &amp; sub-12235 (fmap images with Dim3Size=43, unable to construct fmaps - removing all fmap images for these subjects, see <strong>Iteration 5</strong> above)
   *Note: flag <code class="language-plaintext highlighter-rouge">--use-syn-sdc</code> not included in fmriprep run call, so no susceptibility distortion correction was run for subjects without fieldmaps</li>
          <li>sub-12583 (test sub) doesn‚Äôt have branch in output_ria but is fine in audit
            <ul>
              <li>Path to exemplar outputs: /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/testing/fmriprep/output_ria
 <strong>testing dir deleted to save space on CUBIC on 12/2/21, once production completed</strong></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Production Testing:
        <ul>
          <li>ran <code class="language-plaintext highlighter-rouge">qsub_calls.sh</code>, submitted jobs 1831777 through 1831903</li>
          <li>only 84 files in logfile, 123 branches created under output_ria
            <ul>
              <li>running <code class="language-plaintext highlighter-rouge">merge_outputs.sh</code> and fmriprep-audit to identify failed subj</li>
              <li>edited <code class="language-plaintext highlighter-rouge">concat_outputs.sh</code>(still old version on github) to pull tinashe‚Äôs new <a href="https://raw.githubusercontent.com/PennLINC/RBC/TinasheMTapera-fix-concatenator/PennLINC/Generic/concatenator.py"><code class="language-plaintext highlighter-rouge">concatenator.py</code> edits</a> and edited line 12 ‚Äòconcat_ds/csvs‚Äô to ‚Äòcsvs‚Äô</li>
            </ul>
          </li>
          <li>reviewed <code class="language-plaintext highlighter-rouge">FMRIPREP_AUDIT.csv</code>, 4 subj failed:
            <ul>
              <li>sub-13373 - nipype.workflow ERROR: Node bold_to_std_transform.a0 failed to run on host 2119fmn002‚Ä¶ File ‚Äúindexed_gzip/indexed_gzip.pyx‚Äù, line 635, in indexed_gzip.indexed_gzip._IndexedGzipFile.seek indexed_gzip.indexed_gzip.CrcError: CRC/size validation failed - the GZIP data might be corrupt
                <ul>
                  <li>used <code class="language-plaintext highlighter-rouge">gzip -t -v</code> to validate CRC size for sub-13373_ses-day2_task-face_run-01_bold.nii.gz, OK</li>
                </ul>
              </li>
              <li>sub-14858 - same as above, err on sub-14858_ses-day2_task-card_acq-VARIANTNoFmap_run-02_bold.nii.gz</li>
              <li>sub-15709 - same as above, err on sub-15709_ses-day2_task-rest_bold.nii.gz</li>
              <li>sub-17113 - no error message, log o and e incomplete - to rerun</li>
              <li>removing scans with CRC error, see <strong>Iteration 6</strong> above - pushed BIDS updates to input_ria, rerunning qsub calls for sub-13373 (job 1974456), sub-14858 (job 1974459), sub-15709 (job 1974460), and sub-17113 (job 1974462); ran successfully based on logs, deleted merge_ds and reran <code class="language-plaintext highlighter-rouge">merge_outputs.sh</code>. Regot and reran fmriprep-audit</li>
            </ul>
          </li>
          <li>all 125 subjecs successfully processed</li>
          <li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/BIDS</code></li>
          <li>Path to fmriprep run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/analysis/code/fmriprep_zip.sh</code></li>
          <li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/output_ria</code></li>
          <li>Path to fmriprep production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep-audit/FMRIPREP_AUDIT.csv</code></li>
          <li>Path to freesurfer production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/freesurfer-audit</code>
  ** plotted Euler numbers generated by freesurfer_audit and plotted distribution. Sub-15433 recommended to be excluded from subsequent analyses (Euler=782). Reviewed sub-11305 (238) and sub-11399 (224) with Ted but ok‚Äôd</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>xcp-abcd
    <ul>
      <li>Production Testing:
        <ul>
          <li>edited participant_job.sh, xcp_zip.sh to update python environment, update ‚Äúxcp-abcd-0-0-4‚Äù to ‚Äúxcp-abcd-0-0-8‚Äù (matching container name and Tinashe‚Äôs scripts for other Reward projects)</li>
          <li>ran test subject job 203853 (‚Äúxcpsub-17838‚Äù), successful!</li>
          <li>submitted remaining jobs, successful!</li>
          <li>submitted qsub_calls.sh for xcp-audit</li>
          <li>wget and running bootstrap-quickunzip.sh to clone/unzip xcp outputs to xcp-derivatives; something didn‚Äôt work, seemed to overwrite unzip.sh?
            <ul>
              <li>removed and wgot again, but had typo in path to xcp dir, rerunning with corrected path: <code class="language-plaintext highlighter-rouge">qsub -cwd -N "d2_unzip" bootstrap-quickunzip.sh /cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp</code> - job 213392 (‚Äúd2_unzip‚Äù) has been submitted; job didn‚Äôt seem to run, no outputs; see e and o output files. Rerunning from terminal (not qsub-ed), renamed dir <code class="language-plaintext highlighter-rouge">wolf_satterthwaite_reward</code> to <code class="language-plaintext highlighter-rouge">derivatives-unzipped</code></li>
              <li>concatenated <code class="language-plaintext highlighter-rouge">*space-MNI152NLin6Asym_desc-qc_res-2_bold.csv</code> outputs with <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/notebooks/xcp_qc_concat.ipynb">xcp_qc_concat.ipynb</a>, plotted and saved outputs to github dir qc_plots</li>
            </ul>
          </li>
          <li>Path to production inputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/fmriprep/merge_ds</code></li>
          <li>Path to xcp run command: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/analysis/code/xcp_zip.sh</code></li>
          <li>Path to production outputs: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp/output_ria</code></li>
          <li>Path to xcp production audit: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/xcp-audit/XCP_AUDIT.csv</code></li>
          <li>Path to xcp derivatives: <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/production/derivatives-unzipped/DERIVATIVES/XCP</code></li>
          <li>Path to xcp derivatives (concatenated): <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/curation/code/sandbox/qc_d2.csv</code></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="post-processing">Post Processing</h3>

<ul>
  <li>Who is using the data/for which projects are people in the lab using this data?
    <ul>
      <li>Link to project page(s) here</li>
    </ul>
  </li>
  <li>For each post-processing analysis that has been run on this data, fill out the following
    <ul>
      <li>Who performed the analysis?</li>
      <li>Where it was performed (CUBIC, PMACS, somewhere else)?</li>
      <li>GitHub Link(s) to result(s)</li>
      <li>Did you use pennlinckit?
        <ul>
          <li>https://github.com/PennLINC/PennLINC-Kit/tree/main/pennlinckit</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>FEAT task analysis
    <ul>
      <li>fun side-quest for personal growth run by Margaret Gardner on CUBIC</li>
      <li>wrote .txt timing files using <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl_timing_create.sh">fsl_timing_create.sh</a></li>
      <li>Dan provided original feat analysis files for reference, saved under <code class="language-plaintext highlighter-rouge">fsl_sandbox/dan_orig</code>
        <ul>
          <li>‚Äúthe events folder has all the stickfiles, lots of different variations. the feat directory has a feat directory for this control participant‚Äôs cardA analysis: 11242_03360; the nifti images is that persons 4D bold timeseries used for that feat analysis.‚Äù</li>
        </ul>
      </li>
      <li>running on raw data from 3 subj randomly selected from Acquisition Group 1 (sub-16291, sub-15732, &amp; sub-15761) in <code class="language-plaintext highlighter-rouge">/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox</code> to familiarize with fsl workflow before adapting to accomodate fmriprep outputs; scripts run from git repo directory <code class="language-plaintext highlighter-rouge">fsl</code>
        <ul>
          <li>ran BET on sub-15732 with default settings, pial surface not fully removed - reran with f=0.7 but removed too much, sticking with default f=0.5</li>
          <li>running FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0
            <ul>
              <li>error in Registration: Could not find a supported file with prefix ‚Äú/gpfs/fs001/cbica/projects/wolf_satterthwaite_reward/Margaret/Day2/fsl_sandbox/BIDS/card_run-01.feat/example_func.nii.gz‚Äù</li>
              <li>talked to Greer and discovered error was in bet outputting .hdr/.imgs instead of .nii.gz - need to define FSLOUTPUTTYPE=NIFTI_GZ. Removed all fsl outputs/reverting to raw BIDs to run again</li>
            </ul>
          </li>
          <li>ran BET on sub-15732 with default settings (-f 0.5), extraction looks good</li>
          <li>ran FEAT preprocessing on sub-15732 card run-01: deleting 10 vol, set smoothing to 6.0; successful,</li>
          <li>ran Stats on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1)</li>
          <li>running full analyses on sub-15732 card run-1 with 4 EVs (cue, anticipation, win, lose) and 3 contrasts: (0, 0, 1, 0); (0, 0, 0, 1); (0, 0, 1, -1); successful, removed old feat directories (preprocessing/stats only)</li>
          <li>duplicating/editing design.fsf to github, create seperate design.fsf‚Äôs for each task/run combo (starting with card1, potentially iterate across card/task in the future since they have identical EVs)</li>
          <li>testing <code class="language-plaintext highlighter-rouge">design_card1.fsf</code> on sub-16291, ran successfully</li>
          <li>created design files for each task/run and updated <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a></li>
          <li>ran <a href="https://raw.githubusercontent.com/PennLINC/DAY2_Margaret/main/fsl/run_1stLevel_Analysis.sh">run_1stLevel_Analysis.sh</a> <em>note: outputs and QCs not reviewed since this was for an exercise - would review and/or rerun if intending to use outputs in the future</em>
            <ul>
              <li>removed sub-16291/card1+.feat dir</li>
            </ul>
          </li>
          <li>running 2nd level fixed-effects for card task (averaged across run 1 and 2 for each subj), output to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_2ndLevel.gfeat</code></li>
          <li>running 3rd level FLAME 1 model for card cope 3 (win-lose), default thresholds (cluster z=3.1, p=0.05);  inputs ``fsl_sandbox/card_2ndLevel.gfeat/cope3.feat/stats/cope?.nii.gz<code class="language-plaintext highlighter-rouge">; output to </code>fsl_sandbox/card_3rdLevel_win-lose.gfeat`
            <ul>
              <li>also ran uncorrected analysis to <code class="language-plaintext highlighter-rouge">fsl_sandbox/card_3rdLevel_win-lose_uncorr.gfeat</code> just for fun</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="to-do">To Do</h3>
<ul>
  <li>backup to PMACS</li>
  <li>rename task entity (1 and 2 vs A and B)</li>
  <li>script group level task analyses in FEAT</li>
  <li>bootstrap FEAT analyses for datalad</li>
  <li>adapt feat script to accept fmriprep outputs</li>
</ul>
:ET